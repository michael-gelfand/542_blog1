{
  "hash": "5dddba72be45dfab9fd7dc7d232003a7",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"An in-depth Tutorial on Hyperparameter Optimization in Python\"\nauthor: \"Michael Gelfand\"\ndate: \"2025-01-17\"\ncategories: [Data Science, Tutorials, Python]\nimage: \"image.jpg\"\njupyter: \n  kernel: \"hyperopt_env\"\n---\n\n\n\n\n## **Introduction**\n\n### What is the problem?\nIn the journey of building machine learning models, you may find yourself asking: *What can I do to improve my model’s performance?* While cleaning your dataset, engineering features, and selecting the right algorithm are all critical steps, hyperparameter optimization is often the key to unlocking your model’s full potential.\n\n### Why is hyperparameter optimization important?\nEvery machine learning problem is unique. Different datasets and tasks require specific model settings, called hyperparameters, to achieve the best performance. By fine-tuning these settings, you can maximize your model’s predictive accuracy and efficiency.\n\n### About me and this tutorial\nHi, I’m [Your Name], a data science practitioner passionate about building robust machine learning solutions. In this tutorial, I’ll walk you through the essentials of hyperparameter optimization, demonstrating how to implement grid search and random search in Python with interactive examples.\n\n---\n\n## **Body**\n\n### **What Are Hyperparameters?**\n\nHyperparameters are settings that control how a machine learning model learns from data. Unlike model parameters, which are learned during training, hyperparameters are pre-set before training begins. Some examples include:\n\n- **Learning Rate**: Controls the step size in gradient-based optimization.\n- **Regularization Strength**: Helps prevent overfitting by penalizing large weights.\n- **Max Tree Depth**: Determines the maximum depth of decision trees in ensemble methods like Random Forest.\n\n### **Methods for Optimizing Hyperparameters**\n\nThere are several techniques to find the best hyperparameters for a model. Let’s explore two common approaches:\n\n#### **Grid Search**\n- **Definition**: Exhaustively searches over a predefined grid of hyperparameter values.\n- **Pros**: Guarantees to find the best combination (within the grid).\n- **Cons**: Computationally expensive, especially for large grids.\n- **Use Case**: When you have a rough idea of the hyperparameters’ possible ranges.\n\n#### **Random Search**\n- **Definition**: Samples hyperparameter combinations randomly from predefined distributions.\n- **Pros**: More efficient than grid search, especially for high-dimensional spaces.\n- **Cons**: Doesn’t guarantee the best combination but often finds good enough results.\n- **Use Case**: When you are unsure which hyperparameters are most critical.\n\n### **Tutorial: Hyperparameter Optimization in Python**\n\nLet’s apply these methods to a classification problem using the famous Iris dataset.\n\n#### **1. Dataset and Model Setup**\n\nWe will use a Random Forest Classifier to classify the Iris dataset. Here’s how to load and preprocess the data:\n\n::: {#63f97e3c .cell execution_count=1}\n``` {.python .cell-code}\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Load dataset\niris = load_iris()\nX, y = iris.data, iris.target\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Baseline model\nrf_baseline = RandomForestClassifier(random_state=42)\nrf_baseline.fit(X_train, y_train)\ny_pred_baseline = rf_baseline.predict(X_test)\n\n# Evaluate baseline accuracy\nbaseline_accuracy = accuracy_score(y_test, y_pred_baseline)\nprint(f\"Baseline Accuracy: {baseline_accuracy:.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBaseline Accuracy: 1.00\n```\n:::\n:::\n\n\n#### **2. Grid Search**\n\nNow, let’s optimize the hyperparameters using grid search:\n\n::: {#04a91fb2 .cell execution_count=2}\n``` {.python .cell-code}\nfrom sklearn.model_selection import GridSearchCV\n\n# Define hyperparameter grid\nparam_grid = {\n    'n_estimators': [50, 100, 150],\n    'max_depth': [None, 10, 20],\n    'min_samples_split': [2, 5, 10]\n}\n\n# Initialize GridSearchCV\ngrid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, verbose=2, n_jobs=-1)\n\n# Fit to training data\ngrid_search.fit(X_train, y_train)\n\n# Best parameters and accuracy\nprint(\"Best Parameters:\", grid_search.best_params_)\ngrid_best_model = grid_search.best_estimator_\ny_pred_grid = grid_best_model.predict(X_test)\ngrid_accuracy = accuracy_score(y_test, y_pred_grid)\nprint(f\"Grid Search Accuracy: {grid_accuracy:.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFitting 3 folds for each of 27 candidates, totalling 81 fits\n[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.2s\n[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.2s\n[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.2s\n[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.5s\n[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.4s\n[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.5s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.2s\n[CV] END max_depth=None, min_samples_split=2, n_estimators=150; total time=   0.7s\n[CV] END max_depth=None, min_samples_split=2, n_estimators=150; total time=   0.6s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.2s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.2s\n[CV] END max_depth=None, min_samples_split=2, n_estimators=150; total time=   0.7s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.4s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.5s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.4s\n[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.2s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=150; total time=   0.6s\n[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.2s\n[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.2s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=150; total time=   0.6s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=150; total time=   0.7s\n[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.4s\n[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.4s\n[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.4s\n[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.2s\n[CV] END max_depth=None, min_samples_split=10, n_estimators=150; total time=   0.7s\n[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.3s\n[CV] END max_depth=None, min_samples_split=10, n_estimators=150; total time=   0.7s\n[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.2s\n[CV] END max_depth=None, min_samples_split=10, n_estimators=150; total time=   0.7s\n[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.4s\n[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.4s\n[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.4s\n[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.2s\n[CV] END max_depth=10, min_samples_split=2, n_estimators=150; total time=   0.6s\n[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.2s\n[CV] END max_depth=10, min_samples_split=2, n_estimators=150; total time=   0.6s\n[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.2s\n[CV] END max_depth=10, min_samples_split=2, n_estimators=150; total time=   0.6s\n[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.4s\n[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.4s\n[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.4s\n[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.2s\n[CV] END max_depth=10, min_samples_split=5, n_estimators=150; total time=   0.6s\n[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.2s\n[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.2s\n[CV] END max_depth=10, min_samples_split=5, n_estimators=150; total time=   0.6s\n[CV] END max_depth=10, min_samples_split=5, n_estimators=150; total time=   0.6s\n[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.4s\n[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.4s\n[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.4s\n[CV] END max_depth=10, min_samples_split=10, n_estimators=150; total time=   0.6s\n[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.2s\n[CV] END max_depth=10, min_samples_split=10, n_estimators=150; total time=   0.6s\n[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.2s\n[CV] END max_depth=10, min_samples_split=10, n_estimators=150; total time=   0.6s\n[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.2s\n[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.4s\n[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.4s\n[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.5s\n[CV] END max_depth=20, min_samples_split=2, n_estimators=150; total time=   0.6s\n[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.2s\n[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.2s\n[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.2s\n[CV] END max_depth=20, min_samples_split=2, n_estimators=150; total time=   0.6s\n[CV] END max_depth=20, min_samples_split=2, n_estimators=150; total time=   0.6s\n[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.4s\n[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.4s\n[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.4s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.2s\n[CV] END max_depth=20, min_samples_split=5, n_estimators=150; total time=   0.6s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.2s\n[CV] END max_depth=20, min_samples_split=5, n_estimators=150; total time=   0.6s\n[CV] END max_depth=20, min_samples_split=5, n_estimators=150; total time=   0.6s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.2s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.4s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.4s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.4s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=150; total time=   0.6s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=150; total time=   0.4s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=150; total time=   0.4s\nBest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\nGrid Search Accuracy: 1.00\n```\n:::\n:::\n\n\n#### **3. Random Search**\n\nNext, we use random search for hyperparameter optimization:\n\n::: {#603f08c2 .cell execution_count=3}\n``` {.python .cell-code}\nfrom sklearn.model_selection import RandomizedSearchCV\nimport numpy as np\n\n# Define hyperparameter distribution\nparam_dist = {\n    'n_estimators': np.arange(50, 200, 10),\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10, 15]\n}\n\n# Initialize RandomizedSearchCV\nrandom_search = RandomizedSearchCV(RandomForestClassifier(random_state=42), param_dist, n_iter=50, cv=3, verbose=2, n_jobs=-1, random_state=42)\n\n# Fit to training data\nrandom_search.fit(X_train, y_train)\n\n# Best parameters and accuracy\nprint(\"Best Parameters:\", random_search.best_params_)\nrandom_best_model = random_search.best_estimator_\ny_pred_random = random_best_model.predict(X_test)\nrandom_accuracy = accuracy_score(y_test, y_pred_random)\nprint(f\"Random Search Accuracy: {random_accuracy:.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFitting 3 folds for each of 50 candidates, totalling 150 fits\n[CV] END max_depth=None, min_samples_split=2, n_estimators=110; total time=   0.5s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=140; total time=   0.6s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=140; total time=   0.6s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=140; total time=   0.6s\n[CV] END max_depth=10, min_samples_split=10, n_estimators=80; total time=   0.3s\n[CV] END max_depth=None, min_samples_split=2, n_estimators=110; total time=   0.4s\n[CV] END max_depth=10, min_samples_split=10, n_estimators=80; total time=   0.3s\n[CV] END max_depth=None, min_samples_split=2, n_estimators=110; total time=   0.5s\n[CV] END max_depth=10, min_samples_split=10, n_estimators=80; total time=   0.4s\n[CV] END max_depth=10, min_samples_split=15, n_estimators=90; total time=   0.4s\n[CV] END max_depth=10, min_samples_split=15, n_estimators=90; total time=   0.4s\n[CV] END max_depth=10, min_samples_split=15, n_estimators=90; total time=   0.4s\n[CV] END max_depth=20, min_samples_split=15, n_estimators=120; total time=   0.6s\n[CV] END max_depth=10, min_samples_split=10, n_estimators=190; total time=   0.9s\n[CV] END max_depth=10, min_samples_split=10, n_estimators=190; total time=   0.8s\n[CV] END max_depth=10, min_samples_split=10, n_estimators=190; total time=   0.9s\n[CV] END max_depth=20, min_samples_split=15, n_estimators=120; total time=   0.5s\n[CV] END max_depth=20, min_samples_split=15, n_estimators=120; total time=   0.5s\n[CV] END max_depth=30, min_samples_split=15, n_estimators=130; total time=   0.5s\n[CV] END max_depth=30, min_samples_split=15, n_estimators=130; total time=   0.5s\n[CV] END max_depth=30, min_samples_split=15, n_estimators=130; total time=   0.6s\n[CV] END max_depth=10, min_samples_split=5, n_estimators=160; total time=   0.6s\n[CV] END max_depth=10, min_samples_split=5, n_estimators=160; total time=   0.7s\n[CV] END max_depth=10, min_samples_split=5, n_estimators=160; total time=   0.7s\n[CV] END max_depth=None, min_samples_split=2, n_estimators=140; total time=   0.6s\n[CV] END max_depth=None, min_samples_split=2, n_estimators=140; total time=   0.6s\n[CV] END max_depth=None, min_samples_split=2, n_estimators=140; total time=   0.6s\n[CV] END max_depth=20, min_samples_split=5, n_estimators=130; total time=   0.6s\n[CV] END max_depth=None, min_samples_split=15, n_estimators=50; total time=   0.2s\n[CV] END max_depth=20, min_samples_split=5, n_estimators=130; total time=   0.5s\n[CV] END max_depth=None, min_samples_split=15, n_estimators=50; total time=   0.2s\n[CV] END max_depth=None, min_samples_split=15, n_estimators=50; total time=   0.2s\n[CV] END max_depth=20, min_samples_split=5, n_estimators=130; total time=   0.5s\n[CV] END max_depth=30, min_samples_split=5, n_estimators=160; total time=   0.6s\n[CV] END max_depth=30, min_samples_split=5, n_estimators=160; total time=   0.7s\n[CV] END max_depth=10, min_samples_split=15, n_estimators=140; total time=   0.6s\n[CV] END max_depth=30, min_samples_split=5, n_estimators=160; total time=   0.6s\n[CV] END max_depth=20, min_samples_split=15, n_estimators=80; total time=   0.3s\n[CV] END max_depth=20, min_samples_split=15, n_estimators=80; total time=   0.3s\n[CV] END max_depth=10, min_samples_split=15, n_estimators=140; total time=   0.6s\n[CV] END max_depth=10, min_samples_split=15, n_estimators=140; total time=   0.6s\n[CV] END max_depth=20, min_samples_split=15, n_estimators=80; total time=   0.3s\n[CV] END max_depth=10, min_samples_split=15, n_estimators=130; total time=   0.5s\n[CV] END max_depth=10, min_samples_split=15, n_estimators=130; total time=   0.5s\n[CV] END max_depth=30, min_samples_split=15, n_estimators=100; total time=   0.4s\n[CV] END max_depth=10, min_samples_split=15, n_estimators=130; total time=   0.6s\n[CV] END max_depth=30, min_samples_split=15, n_estimators=100; total time=   0.4s\n[CV] END max_depth=30, min_samples_split=15, n_estimators=100; total time=   0.5s\n[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.4s\n[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.4s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.2s\n[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.4s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.2s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.3s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=70; total time=   0.3s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=70; total time=   0.3s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=70; total time=   0.3s\n[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.4s\n[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.4s\n[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.4s\n[CV] END max_depth=20, min_samples_split=2, n_estimators=120; total time=   0.5s\n[CV] END max_depth=20, min_samples_split=2, n_estimators=120; total time=   0.5s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=90; total time=   0.4s\n[CV] END max_depth=20, min_samples_split=2, n_estimators=120; total time=   0.5s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=90; total time=   0.4s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=90; total time=   0.4s\n[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.2s\n[CV] END max_depth=30, min_samples_split=15, n_estimators=150; total time=   0.6s\n[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.2s\n[CV] END max_depth=30, min_samples_split=15, n_estimators=150; total time=   0.6s\n[CV] END max_depth=30, min_samples_split=15, n_estimators=150; total time=   0.6s\n[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.2s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.2s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.2s\n[CV] END max_depth=20, min_samples_split=15, n_estimators=160; total time=   0.7s\n[CV] END max_depth=20, min_samples_split=15, n_estimators=160; total time=   0.6s\n[CV] END max_depth=20, min_samples_split=15, n_estimators=160; total time=   0.7s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.2s\n[CV] END max_depth=30, min_samples_split=5, n_estimators=110; total time=   0.5s\n[CV] END max_depth=None, min_samples_split=2, n_estimators=150; total time=   0.6s\n[CV] END max_depth=None, min_samples_split=2, n_estimators=150; total time=   0.6s\n[CV] END max_depth=None, min_samples_split=2, n_estimators=150; total time=   0.6s\n[CV] END max_depth=30, min_samples_split=5, n_estimators=110; total time=   0.4s\n[CV] END max_depth=30, min_samples_split=5, n_estimators=110; total time=   0.5s\n[CV] END max_depth=30, min_samples_split=15, n_estimators=170; total time=   0.7s\n[CV] END max_depth=30, min_samples_split=15, n_estimators=170; total time=   0.7s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=80; total time=   0.3s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=80; total time=   0.3s\n[CV] END max_depth=30, min_samples_split=15, n_estimators=170; total time=   0.7s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=80; total time=   0.3s\n[CV] END max_depth=10, min_samples_split=10, n_estimators=110; total time=   0.4s\n[CV] END max_depth=30, min_samples_split=15, n_estimators=80; total time=   0.3s\n[CV] END max_depth=10, min_samples_split=10, n_estimators=110; total time=   0.4s\n[CV] END max_depth=10, min_samples_split=10, n_estimators=110; total time=   0.4s\n[CV] END max_depth=30, min_samples_split=15, n_estimators=80; total time=   0.3s\n[CV] END max_depth=30, min_samples_split=15, n_estimators=80; total time=   0.3s\n[CV] END .max_depth=30, min_samples_split=2, n_estimators=70; total time=   0.3s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=150; total time=   0.6s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=150; total time=   0.6s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=150; total time=   0.6s\n[CV] END .max_depth=30, min_samples_split=2, n_estimators=70; total time=   0.3s\n[CV] END .max_depth=30, min_samples_split=2, n_estimators=70; total time=   0.3s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=80; total time=   0.3s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=80; total time=   0.3s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=80; total time=   0.3s\n[CV] END max_depth=10, min_samples_split=2, n_estimators=140; total time=   0.6s\n[CV] END max_depth=10, min_samples_split=2, n_estimators=140; total time=   0.7s\n[CV] END max_depth=10, min_samples_split=2, n_estimators=140; total time=   0.5s\n[CV] END max_depth=30, min_samples_split=2, n_estimators=170; total time=   0.7s\n[CV] END max_depth=30, min_samples_split=2, n_estimators=170; total time=   0.7s\n[CV] END max_depth=None, min_samples_split=15, n_estimators=150; total time=   0.6s\n[CV] END max_depth=30, min_samples_split=2, n_estimators=170; total time=   0.7s\n[CV] END max_depth=None, min_samples_split=15, n_estimators=150; total time=   0.6s\n[CV] END .max_depth=10, min_samples_split=5, n_estimators=90; total time=   0.4s\n[CV] END .max_depth=10, min_samples_split=5, n_estimators=90; total time=   0.4s\n[CV] END max_depth=None, min_samples_split=15, n_estimators=150; total time=   0.6s\n[CV] END .max_depth=10, min_samples_split=5, n_estimators=90; total time=   0.4s\n[CV] END max_depth=30, min_samples_split=15, n_estimators=70; total time=   0.3s\n[CV] END max_depth=20, min_samples_split=15, n_estimators=150; total time=   0.6s\n[CV] END max_depth=20, min_samples_split=15, n_estimators=150; total time=   0.7s\n[CV] END max_depth=20, min_samples_split=15, n_estimators=150; total time=   0.6s\n[CV] END max_depth=30, min_samples_split=15, n_estimators=70; total time=   0.3s\n[CV] END max_depth=30, min_samples_split=15, n_estimators=70; total time=   0.3s\n[CV] END max_depth=10, min_samples_split=15, n_estimators=120; total time=   0.5s\n[CV] END max_depth=10, min_samples_split=15, n_estimators=120; total time=   0.5s\n[CV] END max_depth=10, min_samples_split=15, n_estimators=120; total time=   0.5s\n[CV] END max_depth=30, min_samples_split=10, n_estimators=160; total time=   0.6s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=60; total time=   0.2s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=60; total time=   0.3s\n[CV] END max_depth=30, min_samples_split=10, n_estimators=160; total time=   0.7s\n[CV] END max_depth=None, min_samples_split=5, n_estimators=60; total time=   0.3s\n[CV] END max_depth=30, min_samples_split=10, n_estimators=160; total time=   0.7s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=110; total time=   0.4s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=110; total time=   0.5s\n[CV] END max_depth=20, min_samples_split=10, n_estimators=110; total time=   0.5s\n[CV] END max_depth=10, min_samples_split=2, n_estimators=110; total time=   0.4s\n[CV] END max_depth=20, min_samples_split=15, n_estimators=50; total time=   0.2s\n[CV] END max_depth=20, min_samples_split=15, n_estimators=50; total time=   0.2s\n[CV] END max_depth=10, min_samples_split=2, n_estimators=110; total time=   0.4s\n[CV] END max_depth=20, min_samples_split=15, n_estimators=50; total time=   0.2s\n[CV] END max_depth=10, min_samples_split=2, n_estimators=110; total time=   0.6s\n[CV] END max_depth=None, min_samples_split=10, n_estimators=130; total time=   0.5s\n[CV] END max_depth=None, min_samples_split=10, n_estimators=130; total time=   0.5s\n[CV] END .max_depth=20, min_samples_split=5, n_estimators=90; total time=   0.4s\n[CV] END max_depth=None, min_samples_split=10, n_estimators=130; total time=   0.5s\n[CV] END .max_depth=20, min_samples_split=5, n_estimators=90; total time=   0.4s\n[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.2s\n[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.2s\n[CV] END .max_depth=20, min_samples_split=5, n_estimators=90; total time=   0.3s\n[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\nBest Parameters: {'n_estimators': np.int64(140), 'min_samples_split': 2, 'max_depth': None}\nRandom Search Accuracy: 1.00\n```\n:::\n:::\n\n\n#### **4. Evaluate Results**\n\nFinally, compare the baseline, grid search, and random search results:\n\n::: {#752e9ecc .cell execution_count=4}\n``` {.python .cell-code}\nprint(f\"Baseline Accuracy: {baseline_accuracy:.2f}\")\nprint(f\"Grid Search Accuracy: {grid_accuracy:.2f}\")\nprint(f\"Random Search Accuracy: {random_accuracy:.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBaseline Accuracy: 1.00\nGrid Search Accuracy: 1.00\nRandom Search Accuracy: 1.00\n```\n:::\n:::\n\n\n---\n\n## **Conclusion**\n\nHyperparameter optimization is a powerful tool for improving machine learning models. As demonstrated, grid search and random search can significantly enhance performance compared to default settings. While grid search is exhaustive, random search is often more practical for larger hyperparameter spaces.\n\nBy mastering these techniques, you’ll be better equipped to tackle diverse machine learning challenges and build more robust models.\n\n---\n\n## **References**\n- Scikit-learn Documentation: https://scikit-learn.org/\n- Bergstra, J., & Bengio, Y. (2012). *Random search for hyper-parameter optimization*. Journal of Machine Learning Research.\n- Python Machine Learning Tutorials on Towards Data Science.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}